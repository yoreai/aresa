//! Streaming Results for Large Queries
//!
//! Provides memory-efficient streaming of large result sets.

use anyhow::Result;
use parking_lot::Mutex;
use std::collections::VecDeque;
use std::sync::Arc;
use tokio::sync::mpsc;
use pin_project_lite::pin_project;
use std::pin::Pin;
use std::task::{Context, Poll};

use crate::storage::{Node, Edge, Value};

/// A cursor for paginated results
#[derive(Debug, Clone)]
pub struct Cursor {
    /// Position in the result set
    pub position: u64,
    /// Unique cursor ID
    pub id: String,
    /// Whether there are more results
    pub has_more: bool,
    /// Page size
    pub page_size: usize,
}

impl Cursor {
    /// Create a new cursor
    pub fn new(page_size: usize) -> Self {
        Self {
            position: 0,
            id: uuid::Uuid::new_v4().to_string(),
            has_more: true,
            page_size,
        }
    }

    /// Advance cursor to next page
    pub fn advance(&mut self, count: usize) {
        self.position += count as u64;
    }

    /// Mark cursor as complete
    pub fn complete(&mut self) {
        self.has_more = false;
    }
}

/// Stream of query results
pub struct ResultStream<T> {
    /// Receiving end of the channel
    receiver: mpsc::Receiver<Result<T>>,
    /// Buffer for prefetched results
    buffer: VecDeque<T>,
    /// Whether the stream is complete
    complete: bool,
}

impl<T> ResultStream<T> {
    /// Create a new result stream
    pub fn new(receiver: mpsc::Receiver<Result<T>>) -> Self {
        Self {
            receiver,
            buffer: VecDeque::new(),
            complete: false,
        }
    }

    /// Get the next result, waiting if necessary
    pub async fn next(&mut self) -> Option<Result<T>> {
        if let Some(item) = self.buffer.pop_front() {
            return Some(Ok(item));
        }

        if self.complete {
            return None;
        }

        match self.receiver.recv().await {
            Some(Ok(item)) => Some(Ok(item)),
            Some(Err(e)) => {
                self.complete = true;
                Some(Err(e))
            }
            None => {
                self.complete = true;
                None
            }
        }
    }

    /// Try to get the next result without waiting
    pub fn try_next(&mut self) -> Option<Result<T>> {
        if let Some(item) = self.buffer.pop_front() {
            return Some(Ok(item));
        }

        if self.complete {
            return None;
        }

        match self.receiver.try_recv() {
            Ok(Ok(item)) => Some(Ok(item)),
            Ok(Err(e)) => {
                self.complete = true;
                Some(Err(e))
            }
            Err(mpsc::error::TryRecvError::Empty) => None,
            Err(mpsc::error::TryRecvError::Disconnected) => {
                self.complete = true;
                None
            }
        }
    }

    /// Collect all remaining results into a Vec
    pub async fn collect(mut self) -> Result<Vec<T>> {
        let mut results = Vec::new();

        while let Some(result) = self.next().await {
            results.push(result?);
        }

        Ok(results)
    }

    /// Check if the stream is complete
    pub fn is_complete(&self) -> bool {
        self.complete
    }
}

/// Sender side of a result stream
pub struct StreamSender<T> {
    /// Sending end of the channel
    sender: mpsc::Sender<Result<T>>,
}

impl<T> StreamSender<T> {
    /// Send a result
    pub async fn send(&self, item: T) -> Result<()> {
        self.sender.send(Ok(item)).await
            .map_err(|_| anyhow::anyhow!("Stream closed"))
    }

    /// Send an error
    pub async fn send_error(&self, error: anyhow::Error) -> Result<()> {
        self.sender.send(Err(error)).await
            .map_err(|_| anyhow::anyhow!("Stream closed"))
    }

    /// Check if receiver is still listening
    pub fn is_closed(&self) -> bool {
        self.sender.is_closed()
    }
}

/// Create a new streaming channel
pub fn create_stream<T>(buffer_size: usize) -> (StreamSender<T>, ResultStream<T>) {
    let (tx, rx) = mpsc::channel(buffer_size);
    (StreamSender { sender: tx }, ResultStream::new(rx))
}

/// Streaming node iterator
pub struct NodeStream {
    inner: ResultStream<Node>,
}

impl NodeStream {
    /// Create from a result stream
    pub fn new(inner: ResultStream<Node>) -> Self {
        Self { inner }
    }

    /// Get next node
    pub async fn next(&mut self) -> Option<Result<Node>> {
        self.inner.next().await
    }

    /// Collect all nodes
    pub async fn collect(self) -> Result<Vec<Node>> {
        self.inner.collect().await
    }
}

/// Streaming edge iterator
pub struct EdgeStream {
    inner: ResultStream<Edge>,
}

impl EdgeStream {
    /// Create from a result stream
    pub fn new(inner: ResultStream<Edge>) -> Self {
        Self { inner }
    }

    /// Get next edge
    pub async fn next(&mut self) -> Option<Result<Edge>> {
        self.inner.next().await
    }

    /// Collect all edges
    pub async fn collect(self) -> Result<Vec<Edge>> {
        self.inner.collect().await
    }
}

/// Batched streaming for efficient network transfer
pub struct BatchedStream<T> {
    inner: ResultStream<Vec<T>>,
    current_batch: VecDeque<T>,
}

impl<T> BatchedStream<T> {
    /// Create a new batched stream
    pub fn new(inner: ResultStream<Vec<T>>) -> Self {
        Self {
            inner,
            current_batch: VecDeque::new(),
        }
    }

    /// Get next item
    pub async fn next(&mut self) -> Option<Result<T>> {
        // First try the current batch
        if let Some(item) = self.current_batch.pop_front() {
            return Some(Ok(item));
        }

        // Fetch next batch
        match self.inner.next().await? {
            Ok(batch) => {
                self.current_batch = batch.into();
                self.current_batch.pop_front().map(Ok)
            }
            Err(e) => Some(Err(e)),
        }
    }

    /// Collect all items
    pub async fn collect(mut self) -> Result<Vec<T>> {
        let mut results = Vec::new();

        while let Some(result) = self.next().await {
            results.push(result?);
        }

        Ok(results)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_result_stream() {
        let (sender, mut stream) = create_stream::<i32>(10);

        // Send some items
        tokio::spawn(async move {
            for i in 0..5 {
                sender.send(i).await.unwrap();
            }
        });

        // Receive items
        let mut results = Vec::new();
        while let Some(Ok(item)) = stream.next().await {
            results.push(item);
        }

        assert_eq!(results, vec![0, 1, 2, 3, 4]);
    }

    #[tokio::test]
    async fn test_stream_collect() {
        let (sender, stream) = create_stream::<String>(10);

        tokio::spawn(async move {
            sender.send("a".to_string()).await.unwrap();
            sender.send("b".to_string()).await.unwrap();
            sender.send("c".to_string()).await.unwrap();
        });

        let results = stream.collect().await.unwrap();
        assert_eq!(results, vec!["a", "b", "c"]);
    }

    #[tokio::test]
    async fn test_batched_stream() {
        let (sender, stream) = create_stream::<Vec<i32>>(10);
        let mut batched = BatchedStream::new(stream);

        tokio::spawn(async move {
            sender.send(vec![1, 2, 3]).await.unwrap();
            sender.send(vec![4, 5]).await.unwrap();
        });

        let results = batched.collect().await.unwrap();
        assert_eq!(results, vec![1, 2, 3, 4, 5]);
    }

    #[test]
    fn test_cursor() {
        let mut cursor = Cursor::new(100);

        assert_eq!(cursor.position, 0);
        assert!(cursor.has_more);

        cursor.advance(50);
        assert_eq!(cursor.position, 50);

        cursor.complete();
        assert!(!cursor.has_more);
    }
}
